{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Dataset\n",
    "\n",
    "1. Start with NETS/LTDB priority dataset For Simplicity\n",
    " - Build a bare bones NETS only, LTDB only, and combined model and then and assess before adding other variables.\n",
    " - This changes our plans regarding years to use in LTDB. Instead of drawing from the 2011-2015 ACS we will use the interpolated LTDB data from the priority dataset\n",
    "2. Subset RECVD data to tracts only available in life expectancy estimation target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables of Interest:\n",
    "\n",
    "In this iteration for both the NETS and LTDB data we will average values from 2010-2014, inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path.cwd().parent / 'data'\n",
    "years = ['2010', '2011', '2012', '2013', '2014']\n",
    "# get colnames that we need\n",
    "\n",
    "with open(data_path / 'raw' / 'T10_Priority_Wide_Interpolated.csv', 'r') as f:\n",
    "    cols = f.readline().strip().split(',')\n",
    "\n",
    "proj_cols = [x for x in cols if x[-4:] in years]\n",
    "\n",
    "data_X = pd.read_csv(data_path / 'raw' / 'T10_Priority_Wide_Interpolated.csv', usecols=proj_cols,\n",
    "                     dtype={'t10_cen_uid_u_2010': \"object\"}) \\\n",
    "                     .set_index('t10_cen_uid_u_2010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y = pd.read_csv(data_path / 'raw' / 'US_A.csv',\n",
    "                    usecols=['Tract ID', 'e(0)'],\n",
    "                    dtype={'Tract ID': \"object\"}) \\\n",
    "    .rename(columns={'Tract ID': 't10_cen_uid_u_2010'}) \\\n",
    "    .set_index('t10_cen_uid_u_2010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_allyrs = data_X.join(data_y, how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns of un-needed geographic vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['t10_gis_area_k_2010',\n",
    " 't10_gis_area_l_2010',\n",
    " 'm10_cen_memi_x_2010',\n",
    " 'm10_cen_uid_u_2010',\n",
    " 'c10_cen_uid_u_2010',\n",
    " 'z10_cen_uid_u_2010']\n",
    "\n",
    "data_allyrs.drop(columns=drop_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Intermediate Priority Dataset to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_priority_allyrs = data_allyrs.iloc[:, :-1] \n",
    "\n",
    "X_priority_allyrs.to_csv(data_path / 'interim' / 'X_priority_allyrs.csv')\n",
    "\n",
    "# no more processing necessary for our target so it goes directly to \"processed\"\n",
    "data_allyrs.iloc[:, -1].to_csv(data_path / 'processed' / 'y_priority.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Variables of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_priority_allyrs.columns = pd.Index([(x[:-5], int(x[-4:])) for x in X_priority_allyrs.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_priority = X_priority_allyrs.groupby(axis=1, level=0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Final Priority Dataset to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_priority.to_csv(data_path / 'processed' / 'X_priority.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
